{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanda1296/Multi-label-text-classification-with-Keras/blob/main/MultiLabel_SequenceClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VamHhunpMiP_",
        "outputId": "2610223c-2abb-4984-e858-04d8cb1ba49d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Cleansing, Feature Engg and 1D CNN code borrowed from https://www.kaggle.com/code/shree77/multi-label-classification"
      ],
      "metadata": {
        "id": "WGAbs2XOvexO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3069af84cb76189b9bf10874ba99d6d1e237bbe5",
        "id": "EtrwpYf6KcC5"
      },
      "cell_type": "markdown",
      "source": [
        "# Multi-label text classification with keras\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true,
        "id": "CT392qWAKcDA"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "import os\n",
        "#print(os.listdir(\"../input\"))\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_df = pd.read_csv(\"drive/My Drive/Colab Notebooks/Data/Questions.csv\", encoding='iso-8859-1')\n",
        "tags_df = pd.read_csv(\"drive/My Drive/Colab Notebooks/Data/Tags.csv\", encoding='iso-8859-1')"
      ],
      "metadata": {
        "id": "kySTsXUY2fxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true,
        "id": "uQM69zAlKcDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "348d5ccb-3df5-415c-f23b-a7e0765f14cd"
      },
      "cell_type": "code",
      "source": [
        "questions_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  OwnerUserId          CreationDate  Score  \\\n",
              "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
              "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
              "2  22         66.0  2010-07-19T19:25:39Z    208   \n",
              "3  31         13.0  2010-07-19T19:28:44Z    138   \n",
              "4  36          8.0  2010-07-19T19:31:47Z     58   \n",
              "\n",
              "                                                                Title  \\\n",
              "0                  The Two Cultures: statistics vs. machine learning?   \n",
              "1                                      Forecasting demographic census   \n",
              "2                 Bayesian and frequentist reasoning in plain English   \n",
              "3  What is the meaning of p values and t values in statistical tests?   \n",
              "4          Examples for teaching: Correlation does not mean causation   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                              Body  \n",
              "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Machine Learning, fight!\"</a> that discussed some of the differences between the two fields.  <a href=\"http://andrewgelman.com/2008/12/machine_learnin/\">Andrew Gelman responded favorably to this</a>:</p>\\...  \n",
              "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?</li>\\n<li>if let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...  \n",
              "2                                                                                                                                                                                                                                                                                       <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n  \n",
              "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the results.  Many computerized tools report test results in terms of \"p ...  \n",
              "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth rate in Denmark;</li>\\n<li>number of priests in America and alcoholism;</li>\\n<li>in the start of the 20th century it was noted that there was a strong correlation between 'Number of radios' and 'Numb...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7235ccb2-a70d-479b-9fd3-e0b18327ea24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2010-07-19T19:14:44Z</td>\n",
              "      <td>272</td>\n",
              "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
              "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Machine Learning, fight!\"&lt;/a&gt; that discussed some of the differences between the two fields.  &lt;a href=\"http://andrewgelman.com/2008/12/machine_learnin/\"&gt;Andrew Gelman responded favorably to this&lt;/a&gt;:&lt;/p&gt;\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>59.0</td>\n",
              "      <td>2010-07-19T19:24:36Z</td>\n",
              "      <td>4</td>\n",
              "      <td>Forecasting demographic census</td>\n",
              "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?&lt;/li&gt;\\n&lt;li&gt;if let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2010-07-19T19:25:39Z</td>\n",
              "      <td>208</td>\n",
              "      <td>Bayesian and frequentist reasoning in plain English</td>\n",
              "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2010-07-19T19:28:44Z</td>\n",
              "      <td>138</td>\n",
              "      <td>What is the meaning of p values and t values in statistical tests?</td>\n",
              "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the results.  Many computerized tools report test results in terms of \"p ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2010-07-19T19:31:47Z</td>\n",
              "      <td>58</td>\n",
              "      <td>Examples for teaching: Correlation does not mean causation</td>\n",
              "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth rate in Denmark;&lt;/li&gt;\\n&lt;li&gt;number of priests in America and alcoholism;&lt;/li&gt;\\n&lt;li&gt;in the start of the 20th century it was noted that there was a strong correlation between 'Number of radios' and 'Numb...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7235ccb2-a70d-479b-9fd3-e0b18327ea24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7235ccb2-a70d-479b-9fd3-e0b18327ea24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7235ccb2-a70d-479b-9fd3-e0b18327ea24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3cb05d6b416914c26d66531e8e521f5e412c11af",
        "collapsed": true,
        "id": "5K1Ah4C3KcDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a19b31-485d-4995-ce20-2772081a026f"
      },
      "cell_type": "code",
      "source": [
        "grouped_tags = tags_df.groupby(\"Tag\", sort='count').size().reset_index(name='count')\n",
        "grouped_tags.Tag.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     1315\n",
              "unique    1315\n",
              "top         2d\n",
              "freq         1\n",
              "Name: Tag, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "93f06b61db6e2b42fd6c1537841f919892211975",
        "id": "7gdRUYkPKcDF"
      },
      "cell_type": "markdown",
      "source": [
        "## Reducing the problem to the most common tags in the dataset\n",
        "We only use the top 20 (arbitrarily picked number) tags because for rare tags there are simply not enough samples available to get reliable results."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "7af43d023d87159a669f6678dc79f4886fb677e9",
        "id": "1TQfB_noKcDF"
      },
      "cell_type": "code",
      "source": [
        "num_classes = 20 #can increase to improve accuracy but training will take longer, while it will increase complexity it will also allow for more data\n",
        "grouped_tags = tags_df.groupby(\"Tag\").size().reset_index(name='count')\n",
        "most_common_tags = grouped_tags.nlargest(num_classes, columns=\"count\")\n",
        "tags_df.Tag = tags_df.Tag.apply(lambda tag : tag if tag in most_common_tags.Tag.values else None)\n",
        "tags_df = tags_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "340f6c140f1e69676e5c63c5af2cc3c9ff31be7d",
        "id": "yTKOlrBOKcDG"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing the contents of the dataframe\n",
        "\n",
        "The question body contains html tags that we don't want to feed into our model. We will thus strip all tags and combine title and question body into a single field for simplicity."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9bed5c95c0a39c535bfb36e721272c40a42077f5",
        "id": "rALjceQlKcDH"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def strip_html_tags(body):\n",
        "    regex = re.compile('<.*?>')\n",
        "    return re.sub(regex, '', body)\n",
        "\n",
        "questions_df['Body'] = questions_df['Body'].apply(strip_html_tags)\n",
        "questions_df['Text'] = questions_df['Title'] + ' ' + questions_df['Body']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "361bcf1624ad1c6c15aa6287772cd1acb6182368",
        "id": "h44LzKnxKcDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "84e0b973-b803-4ee7-c8ce-7364e6c3f74c"
      },
      "cell_type": "code",
      "source": [
        "# denormalize tables\n",
        "\n",
        "def tags_for_question(question_id):\n",
        "    return tags_df[tags_df['Id'] == question_id].Tag.values\n",
        "\n",
        "def add_tags_column(row):\n",
        "    row['Tags'] = tags_for_question(row['Id'])\n",
        "    return row\n",
        "\n",
        "questions_df = questions_df.apply(add_tags_column, axis=1)\n",
        "questions_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  OwnerUserId          CreationDate  Score  \\\n",
              "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
              "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
              "2  22         66.0  2010-07-19T19:25:39Z    208   \n",
              "3  31         13.0  2010-07-19T19:28:44Z    138   \n",
              "4  36          8.0  2010-07-19T19:31:47Z     58   \n",
              "\n",
              "                                                                Title  \\\n",
              "0                  The Two Cultures: statistics vs. machine learning?   \n",
              "1                                      Forecasting demographic census   \n",
              "2                 Bayesian and frequentist reasoning in plain English   \n",
              "3  What is the meaning of p values and t values in statistical tests?   \n",
              "4          Examples for teaching: Correlation does not mean causation   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                              Body  \\\n",
              "0  Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any checking of models and\\n  assumptions'.\\n  -- Brian ...   \n",
              "1  What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far can i forecast it into the\\nfutur...   \n",
              "2                                                                                                                                                                                                                                                                                              How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n   \n",
              "3  After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the results.  Many computerized tools report test results in terms of \"p val...   \n",
              "4  There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between 'Number of radios' and 'Number of people in Insane Asylums'\\n...   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                              Text  \\\n",
              "0  The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any c...   \n",
              "1  Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...   \n",
              "2                                                                                                                                                                                                                                          Bayesian and frequentist reasoning in plain English How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n   \n",
              "3  What is the meaning of p values and t values in statistical tests? After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the resul...   \n",
              "4  Examples for teaching: Correlation does not mean causation There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between 'N...   \n",
              "\n",
              "                   Tags  \n",
              "0    [machine-learning]  \n",
              "1                    []  \n",
              "2            [bayesian]  \n",
              "3  [hypothesis-testing]  \n",
              "4         [correlation]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ecd6949-990c-4435-a163-f5add840f2a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Text</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2010-07-19T19:14:44Z</td>\n",
              "      <td>272</td>\n",
              "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
              "      <td>Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any checking of models and\\n  assumptions'.\\n  -- Brian ...</td>\n",
              "      <td>The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any c...</td>\n",
              "      <td>[machine-learning]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>59.0</td>\n",
              "      <td>2010-07-19T19:24:36Z</td>\n",
              "      <td>4</td>\n",
              "      <td>Forecasting demographic census</td>\n",
              "      <td>What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far can i forecast it into the\\nfutur...</td>\n",
              "      <td>Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2010-07-19T19:25:39Z</td>\n",
              "      <td>208</td>\n",
              "      <td>Bayesian and frequentist reasoning in plain English</td>\n",
              "      <td>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n</td>\n",
              "      <td>Bayesian and frequentist reasoning in plain English How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n</td>\n",
              "      <td>[bayesian]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2010-07-19T19:28:44Z</td>\n",
              "      <td>138</td>\n",
              "      <td>What is the meaning of p values and t values in statistical tests?</td>\n",
              "      <td>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the results.  Many computerized tools report test results in terms of \"p val...</td>\n",
              "      <td>What is the meaning of p values and t values in statistical tests? After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the resul...</td>\n",
              "      <td>[hypothesis-testing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2010-07-19T19:31:47Z</td>\n",
              "      <td>58</td>\n",
              "      <td>Examples for teaching: Correlation does not mean causation</td>\n",
              "      <td>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between 'Number of radios' and 'Number of people in Insane Asylums'\\n...</td>\n",
              "      <td>Examples for teaching: Correlation does not mean causation There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between 'N...</td>\n",
              "      <td>[correlation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ecd6949-990c-4435-a163-f5add840f2a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ecd6949-990c-4435-a163-f5add840f2a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ecd6949-990c-4435-a163-f5add840f2a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3788b41a2b7eae538146f9f59dd2c08ede44889",
        "collapsed": true,
        "id": "AhB8hqpMKcDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "20717645-d44b-4fba-c198-163a1f8c1977"
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 400)\n",
        "questions_df[['Id', 'Text', 'Tags']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  \\\n",
              "0   6   \n",
              "1  21   \n",
              "2  22   \n",
              "3  31   \n",
              "4  36   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                              Text  \\\n",
              "0  The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any c...   \n",
              "1  Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...   \n",
              "2                                                                                                                                                                                                                                          Bayesian and frequentist reasoning in plain English How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n   \n",
              "3  What is the meaning of p values and t values in statistical tests? After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the resul...   \n",
              "4  Examples for teaching: Correlation does not mean causation There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between 'N...   \n",
              "\n",
              "                   Tags  \n",
              "0    [machine-learning]  \n",
              "1                    []  \n",
              "2            [bayesian]  \n",
              "3  [hypothesis-testing]  \n",
              "4         [correlation]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aedf64fd-8f7c-4a9a-b232-68ad73c97813\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Text</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R's fortunes\\n  package: To paraphrase provocatively,\\n  'machine learning is statistics minus\\n  any c...</td>\n",
              "      <td>[machine-learning]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>Bayesian and frequentist reasoning in plain English How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n</td>\n",
              "      <td>[bayesian]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>What is the meaning of p values and t values in statistical tests? After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the resul...</td>\n",
              "      <td>[hypothesis-testing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>Examples for teaching: Correlation does not mean causation There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between 'N...</td>\n",
              "      <td>[correlation]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aedf64fd-8f7c-4a9a-b232-68ad73c97813')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aedf64fd-8f7c-4a9a-b232-68ad73c97813 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aedf64fd-8f7c-4a9a-b232-68ad73c97813');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "80afc34addf7ea5b6e4d08c3af3568d57e21a626",
        "id": "QGGnRUk2KcDL"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenizing the text\n",
        "The text has to be vectorized so that we can feed it into our model. Keras comes with [several text preprocessing classes](https://keras.io/preprocessing/text/) that we can use for that.\n",
        "\n",
        "The labels need encoded as well, so that the 20 labels will be represented as 20 binary values in an array. This can be done with the [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) from the sklearn library."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8bfc23b1e715e60425e861f855d9848e97942069",
        "id": "brMO93lOKcDL"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "multilabel_binarizer = MultiLabelBinarizer()\n",
        "multilabel_binarizer.fit(questions_df.Tags)\n",
        "labels = multilabel_binarizer.classes_\n",
        "\n",
        "maxlen = 80 #can increase to improve accuracy but training will take longer\n",
        "max_words = 3000 #can increase to improve accuracy but training will take longer, also can filter better like use PoS tagger to keep nouns and verbs in these 3k\n",
        "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
        "tokenizer.fit_on_texts(questions_df.Text)\n",
        "\n",
        "def get_features(text_series):\n",
        "    \"\"\"\n",
        "    transforms text data to feature_vectors that can be used in the ml model.\n",
        "    tokenizer must be available.\n",
        "    \"\"\"\n",
        "    sequences = tokenizer.texts_to_sequences(text_series)\n",
        "    return pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "\n",
        "def prediction_to_label(prediction):\n",
        "    tag_prob = [(labels[i], prob) for i, prob in enumerate(prediction.tolist())]\n",
        "    return dict(sorted(tag_prob, key=lambda kv: kv[1], reverse=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ee229fc276c7ef58ee21e06e5d9694bea7f81c8",
        "collapsed": true,
        "id": "NkyVu47_KcDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba82655-1949-43c9-94ad-b633947e7446"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = get_features(questions_df.Text)\n",
        "y = multilabel_binarizer.transform(questions_df.Tags)\n",
        "print(x.shape)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85085, 80)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "0148c095b2f97a53511097f560a07124c2136efb",
        "id": "Qsjq0AbVKcDP"
      },
      "cell_type": "markdown",
      "source": [
        "## Imbalanced Classes\n",
        "Some tags occur more often than others, thus the classes are not well balanced. The imbalanced class problem can be addressed by applying class weights, thus  weighting less frequent tags higher than very frequent tags."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5f0d7d29d627b5f8cd7f18486c3e9cfe93955e9",
        "collapsed": true,
        "id": "A_WoXMX2KcDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "412d067b-cb79-464a-8d9f-d4c9fcb64ba1"
      },
      "cell_type": "code",
      "source": [
        "most_common_tags['class_weight'] = len(tags_df) / most_common_tags['count']\n",
        "class_weight = {}\n",
        "for index, label in enumerate(labels):\n",
        "    class_weight[index] = most_common_tags[most_common_tags['Tag'] == label]['class_weight'].values[0]\n",
        "\n",
        "most_common_tags.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Tag  count  class_weight\n",
              "986                  r  13236      6.046162\n",
              "1020        regression  10959      7.302400\n",
              "669   machine-learning   6089     13.142881\n",
              "1220       time-series   5559     14.395935\n",
              "946        probability   4217     18.977235"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c99fec7d-0e15-4237-b8ab-e2270c2695bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tag</th>\n",
              "      <th>count</th>\n",
              "      <th>class_weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>r</td>\n",
              "      <td>13236</td>\n",
              "      <td>6.046162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>regression</td>\n",
              "      <td>10959</td>\n",
              "      <td>7.302400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>machine-learning</td>\n",
              "      <td>6089</td>\n",
              "      <td>13.142881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1220</th>\n",
              "      <td>time-series</td>\n",
              "      <td>5559</td>\n",
              "      <td>14.395935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>946</th>\n",
              "      <td>probability</td>\n",
              "      <td>4217</td>\n",
              "      <td>18.977235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c99fec7d-0e15-4237-b8ab-e2270c2695bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c99fec7d-0e15-4237-b8ab-e2270c2695bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c99fec7d-0e15-4237-b8ab-e2270c2695bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "9be5f3113d27c68fc9456cb18ba9d38d94bb0ebf",
        "id": "RnC_j_-LKcDQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Building a 1D Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e63351f66ae4bbb63aefd00279d8351e8f7fa8c",
        "collapsed": true,
        "id": "vYkeNML1KcDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe1032f-6d1b-445e-c6a3-b4a421068184"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D, SimpleRNN, GRU, LSTM, Bidirectional\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "filter_length = 300\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    EarlyStopping(patience=4),\n",
        "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    class_weight=class_weight,\n",
        "                    epochs=5, #can increase to improve accuracy but training will take longer\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 80, 20)            60000     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 80, 20)            0         \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 78, 300)           18300     \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 300)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                6020      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 20)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,320\n",
            "Trainable params: 84,320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1915/1915 [==============================] - 50s 25ms/step - loss: 3.9116 - categorical_accuracy: 0.1944 - val_loss: 0.1342 - val_categorical_accuracy: 0.2981 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "1915/1915 [==============================] - 50s 26ms/step - loss: 2.8992 - categorical_accuracy: 0.3243 - val_loss: 0.1269 - val_categorical_accuracy: 0.3186 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "1915/1915 [==============================] - 51s 27ms/step - loss: 2.7434 - categorical_accuracy: 0.3435 - val_loss: 0.1249 - val_categorical_accuracy: 0.3338 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "1915/1915 [==============================] - 58s 30ms/step - loss: 2.6572 - categorical_accuracy: 0.3499 - val_loss: 0.1238 - val_categorical_accuracy: 0.3319 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "1915/1915 [==============================] - 53s 28ms/step - loss: 2.5872 - categorical_accuracy: 0.3545 - val_loss: 0.1232 - val_categorical_accuracy: 0.3377 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41f00f6b8cf514553e442ac6b4d356f69bdc054e",
        "collapsed": true,
        "id": "UxHVn-fDKcDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb898274-3547-4997-861c-5512b9a8ec2f"
      },
      "cell_type": "code",
      "source": [
        "cnn_model = keras.models.load_model('model-conv1d.h5')\n",
        "y_pred = cnn_model.predict(x_test)\n",
        "metrics = cnn_model.evaluate(x_test, y_test)\n",
        "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
        "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "532/532 [==============================] - 4s 8ms/step\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.1215 - categorical_accuracy: 0.3362\n",
            "loss: 0.12152751535177231\n",
            "categorical_accuracy: 0.3361932039260864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "y_pred1 = (y_pred > 0.5)\n",
        "#multilabel_confusion_matrix(y_test, y_pred1, labels=None, sample_weight=None)"
      ],
      "metadata": {
        "id": "SdRm1GJk_HRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred1 = (y_pred > 0.5)\n",
        "print(classification_report(y_test, y_pred1,target_names=most_common_tags.Tag))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg-cLIMbK0dy",
        "outputId": "1a1cbcb3-d15f-4d0a-8a3f-44f22f90664a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                       r       0.68      0.43      0.53       526\n",
            "              regression       0.60      0.46      0.52       525\n",
            "        machine-learning       0.49      0.40      0.44       563\n",
            "             time-series       0.66      0.70      0.68       377\n",
            "             probability       0.61      0.49      0.54       595\n",
            "      hypothesis-testing       0.44      0.07      0.12       705\n",
            "              self-study       0.57      0.18      0.27       736\n",
            "           distributions       0.66      0.50      0.57       657\n",
            "                logistic       0.65      0.07      0.13      1256\n",
            "          classification       0.25      0.01      0.03       371\n",
            "             correlation       0.51      0.54      0.53       405\n",
            "statistical-significance       0.32      0.25      0.28       408\n",
            "                bayesian       0.75      0.58      0.65       382\n",
            "                   anova       0.51      0.26      0.34       481\n",
            "     normal-distribution       0.67      0.15      0.24       846\n",
            "     multiple-regression       0.68      0.38      0.49      2627\n",
            "             mixed-model       0.61      0.33      0.43      2185\n",
            "              clustering       0.46      0.14      0.22       725\n",
            "         neural-networks       0.62      0.07      0.13       520\n",
            " mathematical-statistics       0.69      0.44      0.53      1094\n",
            "\n",
            "               micro avg       0.61      0.31      0.41     15984\n",
            "               macro avg       0.57      0.32      0.38     15984\n",
            "            weighted avg       0.60      0.31      0.39     15984\n",
            "             samples avg       0.24      0.21      0.22     15984\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BiLSTMmodel = Sequential()\n",
        "# Configuring the parameters\n",
        "BiLSTMmodel.add(Embedding(max_words, output_dim=50, input_length=maxlen))\n",
        "BiLSTMmodel.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "# Adding a dropout layer\n",
        "BiLSTMmodel.add(Dropout(0.5))\n",
        "BiLSTMmodel.add(Bidirectional(LSTM(64)))\n",
        "BiLSTMmodel.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "BiLSTMmodel.add(Dense(num_classes))\n",
        "BiLSTMmodel.add(Activation('sigmoid'))\n",
        "\n",
        "BiLSTMmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "BiLSTMmodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4sol2Gcolr",
        "outputId": "9818653a-f3ef-41bd-b9f8-b9c626c9da39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 80, 50)            150000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 80, 256)          183296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 80, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 20)                2580      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 20)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 500,228\n",
            "Trainable params: 500,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    EarlyStopping(patience=4),\n",
        "    ModelCheckpoint(filepath='model-bilstm.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "BiLSTMhistory = BiLSTMmodel.fit(x_train, y_train,\n",
        "                    class_weight=class_weight,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdCHw8WQe67B",
        "outputId": "f7696d35-53ef-4175-af55-d7d1753b8e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1915/1915 [==============================] - 960s 496ms/step - loss: 4.5133 - categorical_accuracy: 0.0772 - val_loss: 0.1855 - val_categorical_accuracy: 0.1106 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model = keras.models.load_model('model-bilstm.h5')\n",
        "y_pred = bilstm_model.predict(x_test)\n",
        "metrics = bilstm_model.evaluate(x_test, y_test)\n",
        "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
        "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QQAI-DBhFU5",
        "outputId": "55701d19-4ed3-436c-9794-7d343bee0c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "532/532 [==============================] - 75s 138ms/step\n",
            "532/532 [==============================] - 76s 140ms/step - loss: 0.1831 - categorical_accuracy: 0.1030\n",
            "loss: 0.1830926537513733\n",
            "categorical_accuracy: 0.10295587033033371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTMmodel = Sequential()\n",
        "# Configuring the parameters\n",
        "LSTMmodel.add(Embedding(max_words, output_dim=50, input_length=maxlen))\n",
        "LSTMmodel.add(LSTM(128, return_sequences=True))\n",
        "# Adding a dropout layer\n",
        "LSTMmodel.add(Dropout(0.5))\n",
        "LSTMmodel.add(LSTM(64))\n",
        "LSTMmodel.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "LSTMmodel.add(Dense(num_classes))\n",
        "LSTMmodel.add(Activation('sigmoid'))\n",
        "\n",
        "LSTMmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "LSTMmodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD_lqFt-OXt_",
        "outputId": "bdc49fa0-246c-4d0a-d59d-d217515fdf93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 80, 50)            150000    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 80, 128)           91648     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 80, 128)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                1300      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 20)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 292,356\n",
            "Trainable params: 292,356\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    EarlyStopping(patience=4),\n",
        "    ModelCheckpoint(filepath='model-lstm.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "LSTMhistory = LSTMmodel.fit(x_train, y_train,\n",
        "                    class_weight=class_weight,\n",
        "                    epochs=2,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cu4bChfRyx7",
        "outputId": "9a70db0a-7009-4931-970b-056418d5ee1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1915/1915 [==============================] - 528s 273ms/step - loss: 4.6342 - categorical_accuracy: 0.0830 - val_loss: 0.1819 - val_categorical_accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 2/2\n",
            "1915/1915 [==============================] - 483s 252ms/step - loss: 4.3213 - categorical_accuracy: 0.0908 - val_loss: 0.1839 - val_categorical_accuracy: 0.1102 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = keras.models.load_model('model-lstm.h5')\n",
        "y_pred = lstm_model.predict(x_test)\n",
        "metrics = lstm_model.evaluate(x_test, y_test)\n",
        "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
        "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfbHqb5nheod",
        "outputId": "18c3cd86-a2fa-4a05-bb74-518f3ad79210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "532/532 [==============================] - 38s 70ms/step\n",
            "532/532 [==============================] - 38s 70ms/step - loss: 0.1799 - categorical_accuracy: 0.1021\n",
            "loss: 0.17990423738956451\n",
            "categorical_accuracy: 0.10213316231966019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRUmodel = Sequential()\n",
        "# Configuring the parameters\n",
        "GRUmodel.add(Embedding(max_words, output_dim=50, input_length=maxlen))\n",
        "GRUmodel.add(GRU(128, return_sequences=True))\n",
        "# Adding a dropout layer\n",
        "GRUmodel.add(Dropout(0.5))\n",
        "GRUmodel.add(GRU(64))\n",
        "GRUmodel.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "GRUmodel.add(Dense(num_classes))\n",
        "GRUmodel.add(Activation('sigmoid'))\n",
        "\n",
        "GRUmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "GRUmodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVnM0RcRiLxd",
        "outputId": "14213dc7-fa4d-4a37-89a9-8e6c12ca6dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 80, 50)            150000    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 80, 128)           69120     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 80, 128)           0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                37248     \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 20)                1300      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 20)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 257,668\n",
            "Trainable params: 257,668\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    EarlyStopping(patience=4),\n",
        "    ModelCheckpoint(filepath='model-gru.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "GRUhistory = GRUmodel.fit(x_train, y_train,\n",
        "                    class_weight=class_weight,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykYo_1XyjAoK",
        "outputId": "4386e6bb-8090-4f1e-991e-398bdc565b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1915/1915 [==============================] - 355s 183ms/step - loss: 4.5674 - categorical_accuracy: 0.0843 - val_loss: 0.1695 - val_categorical_accuracy: 0.1385 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = keras.models.load_model('model-gru.h5')\n",
        "y_pred = gru_model.predict(x_test)\n",
        "metrics = gru_model.evaluate(x_test, y_test)\n",
        "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
        "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6aU0oJIjV0k",
        "outputId": "23b70fe5-97f3-4b70-e451-586df05382ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "532/532 [==============================] - 22s 39ms/step\n",
            "532/532 [==============================] - 22s 40ms/step - loss: 0.1679 - categorical_accuracy: 0.1327\n",
            "loss: 0.16791535913944244\n",
            "categorical_accuracy: 0.13274960219860077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNNmodel = Sequential()\n",
        "# Configuring the parameters\n",
        "RNNmodel.add(Embedding(max_words, output_dim=50, input_length=maxlen))\n",
        "RNNmodel.add(SimpleRNN(128, return_sequences=True))\n",
        "# Adding a dropout layer\n",
        "RNNmodel.add(Dropout(0.5))\n",
        "RNNmodel.add(SimpleRNN(64))\n",
        "RNNmodel.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "RNNmodel.add(Dense(num_classes))\n",
        "RNNmodel.add(Activation('sigmoid'))\n",
        "\n",
        "RNNmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
        "RNNmodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pdqs4uRji8F",
        "outputId": "25e7be27-9cce-4137-d16f-cd60e7b94bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 80, 50)            150000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 80, 128)           22912     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 80, 128)           0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 64)                12352     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 20)                1300      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 20)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 186,564\n",
            "Trainable params: 186,564\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    EarlyStopping(patience=4),\n",
        "    ModelCheckpoint(filepath='model-rnn.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "RNNhistory = RNNmodel.fit(x_train, y_train,\n",
        "                    class_weight=class_weight,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjIESYM7kBXp",
        "outputId": "e3836a8a-6a06-4d40-fafd-42f5c5bc0b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1915/1915 [==============================] - 158s 81ms/step - loss: 4.7871 - categorical_accuracy: 0.0686 - val_loss: 0.1882 - val_categorical_accuracy: 0.0708 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = keras.models.load_model('model-rnn.h5')\n",
        "y_pred = rnn_model.predict(x_test)\n",
        "metrics = rnn_model.evaluate(x_test, y_test)\n",
        "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
        "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78151ZlFkKQP",
        "outputId": "ee5977a4-735b-45be-cb87-c308a5a2eb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "532/532 [==============================] - 9s 17ms/step\n",
            "532/532 [==============================] - 11s 20ms/step - loss: 0.1858 - categorical_accuracy: 0.0668\n",
            "loss: 0.1858353167772293\n",
            "categorical_accuracy: 0.06681554019451141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2L3dB0WXkX9q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}